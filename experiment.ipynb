{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b270bc46",
   "metadata": {},
   "source": [
    "# Ïã§ÌóòÏùÑ ÎèåÎ¶¨Í∏∞ ÏúÑÌïú ÏΩîÎìú\n",
    "ÌïôÏäµÏùÑ ÏßÑÌñâÌïòÍ≥†, ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú inferenceÎ•º ÌÜµÌï¥ submissionÌååÏùºÏùÑ ÎßåÎìúÎäî ÌäúÌÜ†Î¶¨Ïñº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9547c4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8795008  ultralytics.nn.modules.head.Detect           [80, [320, 640, 640]]         \n",
      "YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs\n",
      "\n",
      "New https://pypi.org/project/ultralytics/8.0.124 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.98 üöÄ Python-3.9.12 torch-1.13.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3090, 24268MiB)\n",
      "WARNING ‚ö†Ô∏è Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=./dacon_data.yaml, epochs=400, patience=5, batch=8, imgsz=(1024, 1024), save=True, save_period=-1, cache=True, device=0, workers=16, project=None, name=None, exist_ok=False, pretrained=False, optimizer=Adam, verbose=True, seed=42, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train128\n",
      "Overriding model.yaml nc=80 with nc=34\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8750710  ultralytics.nn.modules.head.Detect           [34, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68185350 parameters, 68185334 gradients, 258.3 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train128', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "WARNING ‚ö†Ô∏è updating to 'imgsz=1024'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/user/dacon_detection/datasets/train/labels.cache... 4171 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (6.6GB True): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4171/4171 [00:29<00:00, 143.27it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/user/dacon_detection/datasets/valid/labels.cache... 2310 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (3.7GB True): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2310/2310 [00:19<00:00, 119.21it/s]\u001b[0m\n",
      "Plotting labels to runs/detect/train128/labels.jpg... \n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train128\u001b[0m\n",
      "Starting training for 400 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/400        16G     0.2771      2.789     0.8617         33       1024:  14%|‚ñà‚ñç        | 74/522 [00:42<04:16,  1."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.rmdir(\"./runs/\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8x.yaml\")  # build a new model from scratch\n",
    "model = YOLO(\"yolov8x.pt\")  # load a pretrained model (recommended for training)\n",
    "#model.model.args['conf'] = 0.7\n",
    "model.model.args['device'] = 0\n",
    "model.model.args['optimizer'] = 'Adam'\n",
    "# Use the model\n",
    "#model.train(data=\"./dacon_data.yaml\", epochs=200,batch=8)  # train the model\n",
    "model.train(data=\"./dacon_data.yaml\",seed=42, epochs=400,batch=8,imgsz=(1024,1024),optimizer='Adam',lr0=1e-3,augment=True,val=True,cache=True,workers=16,patience=5)  # train the model\n",
    "metrics = model.val()  # evaluate model performance on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b2c714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    WARNING ‚ö†Ô∏è stream/video/webcam/dir predict source will accumulate results in RAM unless `stream=True` is passed,\n",
      "    causing potential out-of-memory errors for large sources or long-running streams/videos.\n",
      "\n",
      "    Usage:\n",
      "        results = model(source=..., stream=True)  # generator of Results objects\n",
      "        for r in results:\n",
      "            boxes = r.boxes  # Boxes object for bbox outputs\n",
      "            masks = r.masks  # Masks object for segment masks outputs\n",
      "            probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "3400 labels saved to runs/detect/predict/labels\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"./runs/detect/train123/weights/best.pt\")\n",
    "results = model.predict(source=\"./test\", imgsz=(1024, 1024), iou=0.2, conf=0.5, save_conf=True, save=False, save_txt=True,\n",
    "                  exist_ok=True, device=0, augment=True, verbose=False)\n",
    "#results = model(source=\"./test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964a3b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "res.path.split(\"/\")[-1]: ÏÇ¨ÏßÑ Ïù¥Î¶Ñ\n",
    "res.boxes.cls: class_id\n",
    "res.boxes.conf: confidence score\n",
    "res.boxes.xyxy: lower left, upper right\n",
    "\"\"\"\n",
    "for_submit = []\n",
    "for i in range(len(results)):\n",
    "    n = len(results[i].boxes.cls)\n",
    "    for j in range(n):\n",
    "        x_min, y_min, x_max, y_max = map(int,results[i].boxes.xyxy[j])\n",
    "        #x_min, y_min, x_max, y_max = map(float,results[i].boxes.xyxy[j])\n",
    "        for_submit.append([results[i].path.split(\"/\")[-1], int(results[i].boxes.cls[j]), float(results[i].boxes.conf[j]), x_min, y_max, x_max, y_max, x_max, y_min, x_min, y_min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15403d26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>confidence</th>\n",
       "      <th>point1_x</th>\n",
       "      <th>point1_y</th>\n",
       "      <th>point2_x</th>\n",
       "      <th>point2_y</th>\n",
       "      <th>point3_x</th>\n",
       "      <th>point3_y</th>\n",
       "      <th>point4_x</th>\n",
       "      <th>point4_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>064442001.png</td>\n",
       "      <td>7</td>\n",
       "      <td>0.965588</td>\n",
       "      <td>1138</td>\n",
       "      <td>493</td>\n",
       "      <td>1428</td>\n",
       "      <td>493</td>\n",
       "      <td>1428</td>\n",
       "      <td>181</td>\n",
       "      <td>1138</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>064507368.png</td>\n",
       "      <td>16</td>\n",
       "      <td>0.975452</td>\n",
       "      <td>495</td>\n",
       "      <td>419</td>\n",
       "      <td>762</td>\n",
       "      <td>419</td>\n",
       "      <td>762</td>\n",
       "      <td>124</td>\n",
       "      <td>495</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>065131036.png</td>\n",
       "      <td>22</td>\n",
       "      <td>0.932766</td>\n",
       "      <td>1109</td>\n",
       "      <td>300</td>\n",
       "      <td>1358</td>\n",
       "      <td>300</td>\n",
       "      <td>1358</td>\n",
       "      <td>55</td>\n",
       "      <td>1109</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>065131036.png</td>\n",
       "      <td>33</td>\n",
       "      <td>0.819513</td>\n",
       "      <td>1109</td>\n",
       "      <td>295</td>\n",
       "      <td>1356</td>\n",
       "      <td>295</td>\n",
       "      <td>1356</td>\n",
       "      <td>56</td>\n",
       "      <td>1109</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>065147868.png</td>\n",
       "      <td>16</td>\n",
       "      <td>0.976393</td>\n",
       "      <td>727</td>\n",
       "      <td>491</td>\n",
       "      <td>1011</td>\n",
       "      <td>491</td>\n",
       "      <td>1011</td>\n",
       "      <td>187</td>\n",
       "      <td>727</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name  class_id  confidence  point1_x  point1_y  point2_x  \\\n",
       "0  064442001.png         7    0.965588      1138       493      1428   \n",
       "1  064507368.png        16    0.975452       495       419       762   \n",
       "2  065131036.png        22    0.932766      1109       300      1358   \n",
       "3  065131036.png        33    0.819513      1109       295      1356   \n",
       "4  065147868.png        16    0.976393       727       491      1011   \n",
       "\n",
       "   point2_y  point3_x  point3_y  point4_x  point4_y  \n",
       "0       493      1428       181      1138       181  \n",
       "1       419       762       124       495       124  \n",
       "2       300      1358        55      1109        55  \n",
       "3       295      1356        56      1109        56  \n",
       "4       491      1011       187       727       187  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "submission = pd.DataFrame(for_submit)\n",
    "col = pd.read_csv(\"./sample_submission.csv\").columns\n",
    "submission.columns = col\n",
    "#submission = submission[submission['confidence']>=0.7]\n",
    "submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1f93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sub_dir = \"./submissions/\"\n",
    "file_num = str(len(os.listdir(sub_dir)))\n",
    "submission.to_csv(sub_dir + \"submission\" + file_num + \".csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
